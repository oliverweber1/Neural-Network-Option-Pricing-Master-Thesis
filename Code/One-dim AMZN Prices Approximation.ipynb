{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f529071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook that runs grid searches for different neural network sizes find best hyperparameters \n",
    "with prices of options on the Amazon (AMZN) stock obtained from barchart.com,\n",
    "then trains the models with those parameters and evaluates the performance on unseen data\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tensorflow import keras\n",
    "from tensorflow.random import set_seed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from math import floor\n",
    "from datetime import date\n",
    "from time import time\n",
    "\n",
    "data_path = 'C:\\\\Users\\\\oli-w\\\\OneDrive\\\\Uni\\\\Master Thesis\\\\Neural-Network-Option-Pricing-Master-Thesis\\\\Code\\\\OptionData\\\\'\n",
    "result_path = 'C:\\\\Users\\\\oli-w\\\\OneDrive\\\\Uni\\\\Master Thesis\\\\Neural-Network-Option-Pricing-Master-Thesis\\\\Code\\\\Results\\\\'\n",
    "plot_path = 'C:\\\\Users\\\\oli-w\\\\OneDrive\\\\Uni\\\\Master Thesis\\\\LaTeX Template\\\\'\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "lwidth = 1\n",
    "\n",
    "np.random.seed(seed=123)\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9630da9",
   "metadata": {},
   "source": [
    "# 1 Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b1031",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce87997a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times to expiration\n",
      "[0.33, 1.01, 1.85]\n",
      "AMZN close price at 2022-03-15\n",
      "2947.33\n"
     ]
    }
   ],
   "source": [
    "asof = date(2022, 3, 15) # date of obtained close prices\n",
    "maturities = [date(2022, 7, 15), date(2023, 3, 17), date(2024, 1, 19)]\n",
    "\n",
    "T = {}\n",
    "for d in maturities:\n",
    "    T[np.round((d - asof).days / 365, 2)] = d\n",
    "print('Times to expiration')\n",
    "print(list(T.keys()))\n",
    "\n",
    "s0 = 2947.33\n",
    "print('AMZN close price at {}'.format(asof))\n",
    "print(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df53308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = 0.33\n",
      "Number of data points: Train: 137 Test 35\n",
      "T = 1.01\n",
      "Number of data points: Train: 74 Test 19\n",
      "T = 1.85\n",
      "Number of data points: Train: 124 Test 31\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train-test split for each maturity\n",
    "\"\"\"\n",
    "X = {}\n",
    "y = {}\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "\n",
    "for t in T:\n",
    "    df = pd.read_csv(data_path + 'amzn-options-exp-{}-monthly-show-all-stacked-03-16-2022.csv'.format(T[t]))\n",
    "    df = df[df['Type'] == 'Call']\n",
    "    df['Strike'] = df['Strike'].apply(lambda x: float(x.replace(',', '')))\n",
    "    df['Midpoint'] = df['Midpoint'].apply(lambda x: float(x.replace(',', '')))\n",
    "    df = df[['Strike', 'Midpoint']]\n",
    "    df['Option Norm'] = df['Midpoint'] / df['Strike']\n",
    "    df['Stock Norm'] = s0 / df['Strike']\n",
    "    X[t] = np.array(df['Stock Norm']).reshape((len(df), 1))\n",
    "    y[t] = np.array([df['Option Norm']]).reshape((len(df), 1))\n",
    "    X_train[t], X_test[t], y_train[t], y_test[t] = train_test_split(X[t], y[t], test_size=0.2)\n",
    "    print('T = {}'.format(t))\n",
    "    print('Number of data points: Train: {} Test {}'.format(len(X_train[t]), len(X_test[t])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0537be",
   "metadata": {},
   "source": [
    "## 1.2 Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ac25d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(4, 2.5))\n",
    "ax = fig.add_subplot()\n",
    "fig.tight_layout()\n",
    "ax.margins(x=0)\n",
    "for t in T:\n",
    "    ax.plot(X[t], y[t], label='$T={}$'.format(t), lw=lwidth)\n",
    "ax.set_xlabel('$s_0/K$', fontsize=10)\n",
    "ax.set_ylabel('$C(T,K)/K$', fontsize=10)\n",
    "ax.set_title('Normalized Call Prices on AMZN Stock', fontsize=10)\n",
    "plt.legend(fontsize=10)\n",
    "plt.savefig(plot_path + 'AMZN_Prices.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fedd7",
   "metadata": {},
   "source": [
    "# 2 Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927332ab",
   "metadata": {},
   "source": [
    "## 2.1 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3c6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper function to create model from given number of weights and hidden layers\n",
    "\"\"\"\n",
    "\n",
    "def create_model(hidden_layers=1, learning_rate=0.001, n_weights=10):\n",
    "    # formulas derived from nWeights = sum (d(l-1)+1)*d(l) for all layers l with output dim d(l)\n",
    "    \n",
    "    if hidden_layers == 1: # 100% of neurons in first hidden layer\n",
    "        neurons = [floor((n_weights - 1) / 3)]\n",
    "    elif hidden_layers == 2: # 70% / 30% split of neurons\n",
    "        x = 1/7 * (np.sqrt(21 * n_weights + 79) - 10)\n",
    "        neurons = list(map(floor,[7/3 * x, x]))\n",
    "    elif hidden_layers == 3: # 50% / 30% / 20% split\n",
    "        x = 1/21 * (np.sqrt(84 * n_weights + 205) - 17)\n",
    "        neurons = list(map(floor, [5/2 * x, 3/2 * x, x]))\n",
    "    else:\n",
    "        raise Exception('Only 1, 2 or 3 layers allowed')\n",
    "        \n",
    "    model = Sequential([Dense(neurons[0], activation='relu', input_dim=1)])\n",
    "    for n in neurons[1:]:\n",
    "        model.add(Dense(n, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793089ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs grid search for given train and test data with network of given size\n",
    "\"\"\"\n",
    "\n",
    "def run_grid_search(X_train, y_train, n_weights, n_epochs):\n",
    "    \n",
    "    batch_size = [8, 16, 32, 64]\n",
    "    learning_rate = [0.1, 0.01, 0.001, 0.0001]\n",
    "    hidden_layers = [1, 2, 3]\n",
    "\n",
    "    p_grid = dict(hidden_layers=hidden_layers, batch_size=batch_size, learning_rate=learning_rate, epochs=n_epochs)\n",
    "    \n",
    "    def creator(hidden_layers, learning_rate): return create_model(hidden_layers, learning_rate, n_weights)\n",
    "    \n",
    "    model = KerasRegressor(creator, verbose=0)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=p_grid, n_jobs=-1, cv=4, verbose=3)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    print('Best: {} using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "    return grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8feded9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saves performance result for all parameters and best results for each network size\n",
    "\"\"\"\n",
    "\n",
    "def save_results(result_dict, maturity):\n",
    "\n",
    "    columns = ['mean_fit_time', 'param_batch_size', 'param_hidden_layers', 'param_learning_rate', \n",
    "                'param_epochs', 'mean_test_score', 'rank_test_score']\n",
    "    dfs = []\n",
    "    best_dfs = []\n",
    "    for n in result_dict.keys():\n",
    "        df = pd.DataFrame(result_dict[n].cv_results_)[columns]\n",
    "        df['n_weights'] = n\n",
    "        df.columns = ['Training Time (s)', 'Batch Size', 'Hidden Layers', 'Learning Rate', 'Epochs',\n",
    "                      'Validation MSE', 'Rank', 'Weights']\n",
    "        df = df[['Weights', 'Validation MSE', 'Hidden Layers', 'Learning Rate', 'Batch Size',\n",
    "                 'Epochs', 'Training Time (s)', 'Rank']]\n",
    "        df['Validation MSE'] = (-df['Validation MSE']).apply(lambda x: '{:.3e}'.format(x))\n",
    "        dfs.append(df)\n",
    "        best_dfs.append(df[df['Rank'] == 1].drop(['Rank'], axis=1))\n",
    "    result_df = pd.concat(dfs).reset_index(drop=True)\n",
    "    best_result_df = pd.concat(best_dfs).reset_index(drop=True)\n",
    "    result_df.to_csv(result_path + 'one_dim_AMZN_{}_grid_search_all_results.csv'.format(maturity), index=False)\n",
    "    best_result_df.to_csv(result_path + 'one_dim_AMZN_{}_grid_search_overview.csv'.format(maturity), index=False)\n",
    "    return best_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c5c33",
   "metadata": {},
   "source": [
    "## 2.1 Perform Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0f8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = {10: [10, 25, 50, 100],\n",
    "               30: [10, 25, 50, 100],\n",
    "               60: [10, 25, 50, 100],\n",
    "               100: [10, 25, 50, 100],\n",
    "               300: [20, 50, 100, 150],\n",
    "               600: [20, 50, 100, 150],\n",
    "               1000: [20, 50, 100, 150],\n",
    "               3000: [50, 100, 150, 200],\n",
    "               6000: [50, 100, 150, 200],\n",
    "               10000: [50, 100, 175, 300],\n",
    "               30000: [100, 175, 300, 500]}\n",
    "\n",
    "n_weights = n_epochs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26bc3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = 0.33\n",
      "Network Size = 10\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -0.0009674137281763251 using {'batch_size': 16, 'epochs': 25, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 30\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -0.0001920194954436738 using {'batch_size': 8, 'epochs': 100, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 60\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -2.044089796982007e-05 using {'batch_size': 16, 'epochs': 25, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 100\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -3.798362843099312e-05 using {'batch_size': 16, 'epochs': 50, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 300\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -5.226648113421106e-06 using {'batch_size': 64, 'epochs': 150, 'hidden_layers': 3, 'learning_rate': 0.01}\n",
      "Network Size = 600\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -6.483124820988451e-06 using {'batch_size': 8, 'epochs': 150, 'hidden_layers': 3, 'learning_rate': 0.001}\n",
      "Network Size = 1000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -5.710250860602173e-06 using {'batch_size': 8, 'epochs': 150, 'hidden_layers': 3, 'learning_rate': 0.001}\n",
      "Network Size = 3000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -7.817941423127195e-07 using {'batch_size': 8, 'epochs': 200, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 6000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -6.539885646361654e-07 using {'batch_size': 64, 'epochs': 200, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 10000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -3.3232000795635486e-07 using {'batch_size': 64, 'epochs': 175, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 30000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -1.8901529941217632e-07 using {'batch_size': 64, 'epochs': 500, 'hidden_layers': 3, 'learning_rate': 0.001}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>Validation MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>9.674e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>1.494752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1.920e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>3.416613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>2.044e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>1.406987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>3.798e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>1.611690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>5.227e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>150</td>\n",
       "      <td>2.093899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>6.483e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>6.163267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>5.710e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>6.535271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000</td>\n",
       "      <td>7.818e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>7.358070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6000</td>\n",
       "      <td>6.540e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>2.982524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>3.323e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>175</td>\n",
       "      <td>3.511858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30000</td>\n",
       "      <td>1.890e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>500</td>\n",
       "      <td>5.983746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weights Validation MSE Hidden Layers Learning Rate Batch Size Epochs  \\\n",
       "0        10      9.674e-04             1           0.1         16     25   \n",
       "1        30      1.920e-04             1          0.01          8    100   \n",
       "2        60      2.044e-05             1           0.1         16     25   \n",
       "3       100      3.798e-05             1           0.1         16     50   \n",
       "4       300      5.227e-06             3          0.01         64    150   \n",
       "5       600      6.483e-06             3         0.001          8    150   \n",
       "6      1000      5.710e-06             3         0.001          8    150   \n",
       "7      3000      7.818e-07             1          0.01          8    200   \n",
       "8      6000      6.540e-07             1          0.01         64    200   \n",
       "9     10000      3.323e-07             1          0.01         64    175   \n",
       "10    30000      1.890e-07             3         0.001         64    500   \n",
       "\n",
       "    Training Time (s)  \n",
       "0            1.494752  \n",
       "1            3.416613  \n",
       "2            1.406987  \n",
       "3            1.611690  \n",
       "4            2.093899  \n",
       "5            6.163267  \n",
       "6            6.535271  \n",
       "7            7.358070  \n",
       "8            2.982524  \n",
       "9            3.511858  \n",
       "10           5.983746  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = 1.01\n",
      "Network Size = 10\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -0.0035686590999830514 using {'batch_size': 16, 'epochs': 10, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 30\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -0.0002678500441106735 using {'batch_size': 16, 'epochs': 50, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 60\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oli-w\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.507345758815063e-05 using {'batch_size': 8, 'epochs': 50, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 100\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -1.8458411148003506e-05 using {'batch_size': 8, 'epochs': 25, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 300\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -2.909075033130648e-05 using {'batch_size': 8, 'epochs': 100, 'hidden_layers': 2, 'learning_rate': 0.01}\n",
      "Network Size = 600\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -1.6063458588178037e-05 using {'batch_size': 8, 'epochs': 150, 'hidden_layers': 3, 'learning_rate': 0.01}\n",
      "Network Size = 1000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -6.453494052038877e-06 using {'batch_size': 8, 'epochs': 50, 'hidden_layers': 3, 'learning_rate': 0.01}\n",
      "Network Size = 3000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -2.6494131759591255e-06 using {'batch_size': 8, 'epochs': 150, 'hidden_layers': 3, 'learning_rate': 0.001}\n",
      "Network Size = 6000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -1.5851332761940284e-06 using {'batch_size': 32, 'epochs': 100, 'hidden_layers': 3, 'learning_rate': 0.01}\n",
      "Network Size = 10000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -3.964560164604336e-07 using {'batch_size': 32, 'epochs': 300, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 30000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -2.402804426537841e-07 using {'batch_size': 64, 'epochs': 500, 'hidden_layers': 2, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>Validation MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3.569e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1.759793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>2.679e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>1.543621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>5.507e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>1.720898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1.846e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>1.956019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>2.909e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>2.725959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>1.606e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>4.058894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>6.453e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>2.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000</td>\n",
       "      <td>2.649e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>4.132697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6000</td>\n",
       "      <td>1.585e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>2.077693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>3.965e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>300</td>\n",
       "      <td>3.576184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30000</td>\n",
       "      <td>2.403e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>500</td>\n",
       "      <td>4.671756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weights Validation MSE Hidden Layers Learning Rate Batch Size Epochs  \\\n",
       "0        10      3.569e-03             1           0.1         16     10   \n",
       "1        30      2.679e-04             1           0.1         16     50   \n",
       "2        60      5.507e-05             1           0.1          8     50   \n",
       "3       100      1.846e-05             1           0.1          8     25   \n",
       "4       300      2.909e-05             2          0.01          8    100   \n",
       "5       600      1.606e-05             3          0.01          8    150   \n",
       "6      1000      6.453e-06             3          0.01          8     50   \n",
       "7      3000      2.649e-06             3         0.001          8    150   \n",
       "8      6000      1.585e-06             3          0.01         32    100   \n",
       "9     10000      3.965e-07             1          0.01         32    300   \n",
       "10    30000      2.403e-07             2          0.01         64    500   \n",
       "\n",
       "    Training Time (s)  \n",
       "0            1.759793  \n",
       "1            1.543621  \n",
       "2            1.720898  \n",
       "3            1.956019  \n",
       "4            2.725959  \n",
       "5            4.058894  \n",
       "6            2.056500  \n",
       "7            4.132697  \n",
       "8            2.077693  \n",
       "9            3.576184  \n",
       "10           4.671756  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = 1.85\n",
      "Network Size = 10\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -0.0012094256526324898 using {'batch_size': 8, 'epochs': 25, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 30\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -0.00018042039664578624 using {'batch_size': 16, 'epochs': 100, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 60\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -2.61035288531275e-05 using {'batch_size': 64, 'epochs': 100, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 100\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -3.568811121112958e-05 using {'batch_size': 8, 'epochs': 25, 'hidden_layers': 1, 'learning_rate': 0.1}\n",
      "Network Size = 300\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -1.7045175127350376e-05 using {'batch_size': 8, 'epochs': 100, 'hidden_layers': 3, 'learning_rate': 0.01}\n",
      "Network Size = 600\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oli-w\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -9.471754879086802e-06 using {'batch_size': 32, 'epochs': 100, 'hidden_layers': 3, 'learning_rate': 0.01}\n",
      "Network Size = 1000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -3.5491095218276314e-06 using {'batch_size': 8, 'epochs': 150, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 3000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -1.1145138003598731e-06 using {'batch_size': 32, 'epochs': 100, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 6000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -9.865632364380872e-07 using {'batch_size': 32, 'epochs': 150, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 10000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n",
      "Best: -2.1598921673415816e-07 using {'batch_size': 64, 'epochs': 175, 'hidden_layers': 1, 'learning_rate': 0.01}\n",
      "Network Size = 30000\n",
      "Fitting 4 folds for each of 192 candidates, totalling 768 fits\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for t in T:\n",
    "    print('T = {}'.format(t))\n",
    "    results[t] = {}\n",
    "    for n in n_weights:\n",
    "        print('Network Size = {}'.format(n))\n",
    "        results[t][n] = run_grid_search(X_train[t], y_train[t], n, n_epochs[n])\n",
    "    results[t] = save_results(results[t], t)\n",
    "    display(results[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd442f",
   "metadata": {},
   "source": [
    "# Run Models on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f8f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains and evaluates all models with best parameters (from grid search) for a given pricing model and maturity\n",
    "with early stopping\n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "def run_tests(df_overview, X_train, y_train, X_test, y_test, maturity):\n",
    "    test_mse = []\n",
    "    train_epochs = []\n",
    "    train_time = []\n",
    "    earlyStop = keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)    \n",
    "    for weights, hidden, lr, batch in zip(df_overview['Weights'], df_overview['Hidden Layers'], \n",
    "                                          df_overview['Learning Rate'], df_overview['Batch Size']):\n",
    "        model = create_model(hidden, float(lr), weights)\n",
    "        start = time()\n",
    "        hist = model.fit(X_train, y_train, epochs=5000, batch_size=batch, verbose=0, callbacks=[earlyStop])\n",
    "        train_time.append(time() - start)\n",
    "        test_mse.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "        train_epochs.append(hist.epoch[-1])\n",
    "    df_overview['Test MSE'] = test_mse\n",
    "    df_overview['Epochs (Early Stop)'] = train_epochs\n",
    "    df_overview['Training Time (s)'] = train_time\n",
    "    df_test = df_overview[['Weights', 'Test MSE', 'Hidden Layers', 'Learning Rate', 'Batch Size',\n",
    "                           'Epochs (Early Stop)', 'Training Time (s)']]\n",
    "    df_test['Test MSE'] = df_test['Test MSE'].apply(lambda x: '{:.3e}'.format(x))\n",
    "    df_test.to_csv(result_path + 'one_dim_AMZN_{}_test_overview.csv'.format(maturity), index=False)\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63768191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load all grid search overviews\n",
    "\"\"\"\n",
    "\n",
    "overviews = {}\n",
    "\n",
    "for t in T:\n",
    "    overviews[t] = pd.read_csv(result_path + 'one_dim_AMZN_{}_grid_search_overview.csv'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebde48b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933DB96B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933E120B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933F6D6040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933DEC08B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933F3DBEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933DB965E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C8CDEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oli-w\\AppData\\Local\\Temp/ipykernel_16712/3207884252.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['Test MSE'] = df_test['Test MSE'].apply(lambda x: '{:.3e}'.format(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Epochs (Early Stop)</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3.137e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.399871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1.087e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>1.419977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>6.173e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>0.499891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>4.028e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>0.475750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>2.990e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>0.568719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>3.657e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>1.545657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.897e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>1.908780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000</td>\n",
       "      <td>1.164e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>0.989349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6000</td>\n",
       "      <td>1.167e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.809871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>2.885e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>113</td>\n",
       "      <td>0.937490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30000</td>\n",
       "      <td>1.820e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>79</td>\n",
       "      <td>0.682409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weights   Test MSE  Hidden Layers  Learning Rate  Batch Size  \\\n",
       "0        10  3.137e-03              1          0.100          16   \n",
       "1        30  1.087e-04              1          0.010           8   \n",
       "2        60  6.173e-06              1          0.100          16   \n",
       "3       100  4.028e-05              1          0.100          16   \n",
       "4       300  2.990e-05              3          0.010          64   \n",
       "5       600  3.657e-06              3          0.001           8   \n",
       "6      1000  1.897e-06              3          0.001           8   \n",
       "7      3000  1.164e-06              1          0.010           8   \n",
       "8      6000  1.167e-06              1          0.010          64   \n",
       "9     10000  2.885e-07              1          0.010          64   \n",
       "10    30000  1.820e-06              3          0.001          64   \n",
       "\n",
       "    Epochs (Early Stop)  Training Time (s)  \n",
       "0                    10           0.399871  \n",
       "1                   106           1.419977  \n",
       "2                    24           0.499891  \n",
       "3                    19           0.475750  \n",
       "4                    65           0.568719  \n",
       "5                    96           1.545657  \n",
       "6                   118           1.908780  \n",
       "7                    39           0.989349  \n",
       "8                   128           0.809871  \n",
       "9                   113           0.937490  \n",
       "10                   79           0.682409  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933FA625E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x0000029339878CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C8CDD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933DB96B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933DEC0280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933F6D6940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C8CD040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933E1209D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933DEC05E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C697550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933FCFC9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oli-w\\AppData\\Local\\Temp/ipykernel_16712/3207884252.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['Test MSE'] = df_test['Test MSE'].apply(lambda x: '{:.3e}'.format(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Epochs (Early Stop)</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4.186e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.331113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1.773e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>66</td>\n",
       "      <td>0.769904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>7.382e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.381044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1.361e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.397964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>6.442e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.407873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>7.324e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.720228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.530e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.667225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000</td>\n",
       "      <td>1.348e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>0.964459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6000</td>\n",
       "      <td>3.401e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0.746962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.695e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>0.599396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30000</td>\n",
       "      <td>1.088e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>119</td>\n",
       "      <td>0.842747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weights   Test MSE  Hidden Layers  Learning Rate  Batch Size  \\\n",
       "0        10  4.186e-03              1          0.100          16   \n",
       "1        30  1.773e-04              1          0.100          16   \n",
       "2        60  7.382e-05              1          0.100           8   \n",
       "3       100  1.361e-04              1          0.100           8   \n",
       "4       300  6.442e-05              2          0.010           8   \n",
       "5       600  7.324e-05              3          0.010           8   \n",
       "6      1000  1.530e-01              3          0.010           8   \n",
       "7      3000  1.348e-03              3          0.001           8   \n",
       "8      6000  3.401e-06              3          0.010          32   \n",
       "9     10000  1.695e-06              1          0.010          32   \n",
       "10    30000  1.088e-05              2          0.010          64   \n",
       "\n",
       "    Epochs (Early Stop)  Training Time (s)  \n",
       "0                    20           0.331113  \n",
       "1                    66           0.769904  \n",
       "2                    17           0.381044  \n",
       "3                    18           0.397964  \n",
       "4                    18           0.407873  \n",
       "5                    43           0.720228  \n",
       "6                    17           0.667225  \n",
       "7                    55           0.964459  \n",
       "8                    87           0.746962  \n",
       "9                    54           0.599396  \n",
       "10                  119           0.842747  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C40C3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933B080700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C3633A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933E120CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933F6D6A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C697940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933C40C280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933E120C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933DB96DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933FCFCE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002933F62C670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oli-w\\AppData\\Local\\Temp/ipykernel_16712/3207884252.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['Test MSE'] = df_test['Test MSE'].apply(lambda x: '{:.3e}'.format(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Epochs (Early Stop)</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2.413e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>0.826105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1.242e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>0.418949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>5.444e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "      <td>0.320245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1.498e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.457748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>1.227e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.678182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>1.413e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>78</td>\n",
       "      <td>0.942507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>4.170e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.554768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000</td>\n",
       "      <td>3.211e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>57</td>\n",
       "      <td>0.505115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6000</td>\n",
       "      <td>1.981e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>74</td>\n",
       "      <td>0.598614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.397e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>0.347594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30000</td>\n",
       "      <td>2.534e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>86</td>\n",
       "      <td>0.739041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weights   Test MSE  Hidden Layers  Learning Rate  Batch Size  \\\n",
       "0        10  2.413e-03              1          0.010           8   \n",
       "1        30  1.242e-04              1          0.100          16   \n",
       "2        60  5.444e-03              1          0.100          64   \n",
       "3       100  1.498e-05              1          0.100           8   \n",
       "4       300  1.227e-01              3          0.010           8   \n",
       "5       600  1.413e-05              3          0.010          32   \n",
       "6      1000  4.170e-05              1          0.010           8   \n",
       "7      3000  3.211e-06              1          0.010          32   \n",
       "8      6000  1.981e-06              1          0.010          32   \n",
       "9     10000  1.397e-04              1          0.010          64   \n",
       "10    30000  2.534e-06              3          0.001          32   \n",
       "\n",
       "    Epochs (Early Stop)  Training Time (s)  \n",
       "0                    38           0.826105  \n",
       "1                    26           0.418949  \n",
       "2                    25           0.320245  \n",
       "3                    15           0.457748  \n",
       "4                    11           0.678182  \n",
       "5                    78           0.942507  \n",
       "6                    25           0.554768  \n",
       "7                    57           0.505115  \n",
       "8                    74           0.598614  \n",
       "9                    27           0.347594  \n",
       "10                   86           0.739041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run tests on AMZN data\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(seed=123)\n",
    "set_seed(1234)\n",
    "\n",
    "tests = {}\n",
    "\n",
    "for t in T:\n",
    "    tests[t] = run_tests(overviews[t], X_train[t], y_train[t], X_test[t], y_test[t], t)\n",
    "    display(tests[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4bdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
